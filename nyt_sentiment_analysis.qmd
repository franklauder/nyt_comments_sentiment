---
title: "Sentiment Analysis of 2017 New York Times Comments "
format: html
---

# Introduction

# Data Inspection

```{r}

library(dplyr)
library(ggplot2)
library(treemapify)
library(plotly)

library(tidyr)
library(tidytext)
library(SnowballC)

library(textmineR)
library(textstem)
library(tm)
library(syuzhet)

library(tibble)

library(textclean)
library(furrr)


```






```{r}


nyt_comments17 |> 
    glimpse()


```


```{r}


nyt_comments17<-read.csv("nyt_comments17.csv")


```


```{r}


nyt_comments17 |> head()


```

```{r}

saveRDS(nyt_comments17, "nyt_comments17.rds")


```

```{r}


nyt_comments17_short<-nyt_comments17 |> 
    select(-commentType)



```

We will remove the column commentType


```{r}

nyt_comments17_short |> 
    glimpse()



```

```{r}


saveRDS(nyt_comments17_short, "nyt_comments17_short.rds")


```

# Data Preparation


We will need a function to clean the text in the New York Times commentBody.  




```{r}

clean_comment_text <- function(text) {
  text %>%
    gsub("<.*?>", " ", .) %>%                  # Remove HTML/Markdown tags like <br/>
    gsub("\\\\", " ", .) %>%                   # Remove backslashes
    gsub("[^\\p{L}\\p{N}\\s!?\\p{Emoji_Presentation}]", " ", ., perl = TRUE) %>%  
    gsub("\\s+", " ", .) %>%                   # Replace multiple spaces with single space
    trimws()
}



```

```{r}


nyt_comments_clean<-nyt_comments17_short |> 
    mutate(clean_comments = clean_comment_text(commentBody))


```



```{r}


nyt_comments_clean |> 
    glimpse()



```

```{r}

saveRDS(nyt_comments_clean, "nyt_comments_clean.rds")


```


# Sentiment extraction


```{r}


nyt_comments_clean<-readRDS("nyt_comments_clean.rds")



```

```{r}


nrow(nyt_comments_clean)

```


Because the dataset is relatively large at 969,655 rows, we will use parallel processing for efficency and speed during sentiment extraction. 
 To accomplish this we will use the future_map_dbl function from the the furrr library.  This function helps use cpu cores to parallel tasks. 
 All but one cpu core will be used for our processing. 


  ```{r}
  

plan(multisession, workers = parallel::detectCores() - 1)


  ```

Now that we have set up our parallel processing we will extract sentiments from the clean_comment column of our dataset using the get_sentiment function from the syuzhet library.  The afinn method will be used for labeling the sentiment of each row of comments.  Afinn assigns a sentiment score for each row, ranging fron -5 to 5. 

  ```{r}
  
comments17_sentiment<-nyt_comments_clean |> 
    mutate(
        sentiment_score=future_map_dbl(clean_comments, get_sentiment, method = "afinn")
    )


  ```


  ```{r}
  

comments17_sentiment |> glimpse()


  ```


  Using glimpse we see that there is a sentiment_score column.


  ```{r}
  

comments17_sentiment |> 
    select(commentID, sentiment_score) |> 
    head(30)


  ```

  Now that we have sentiment scores our next step is to assign a sentiment based on these scores.  Negative scores will be assigned a sentiment of "negative", positive scores will be assigned a sentiment of "positive", and a score of zero will be assigned "nuetral".  This will be done using the case_when function from the dplyr library.


  ```{r}
  

comments17_sentiment<-comments17_sentiment %>% 
  mutate(sentiment=case_when(
    sentiment_score > 0 ~ "positive",
    sentiment_score < 0 ~ "negative",
    TRUE ~ "neutral"
  ))



  ```


  ```{r}
  

saveRDS(comments17_sentiment, "comments17_sentiment.rds")


  ```


  ```{r}
  
comments17_sentiment |> 
    glimpse()


  ```


  ```{r}
  

comments17_sentiment |> 
    select(commentID, sentiment) |> 
    head(30)

  ```


  # Sentiment Review






  ```{r}
  

comments17_sentiment |> 
    count(sentiment, sort=TRUE, name="Count") |> 
    mutate(percent=round(Count/sum(Count),2))



  ```





  ```{r}
  

comments17_sentiment |> 
    count(sentiment,newDesk, sort=TRUE, name="Count") |> 
    mutate(percent=round(Count/sum(Count),2))



  ```



  ```{r}
  


sentiment_tree<-comments17_sentiment |> 
  count(sentiment) |> 
  mutate(perc = round(n/sum(n),3)*100)


  
  ```


  ```{r}
  
  
  tree_map<-ggplot(sentiment_tree, aes(area=perc, fill = sentiment, label=perc))+
  geom_treemap()+
  geom_treemap_text()+
  ggtitle("Sentiment (Percent)")+
  theme(plot.title = element_text(color="black", size=14, face="bold.italic", hjust=0.5))+
  scale_fill_discrete(name = "Sentiment")+
  scale_y_continuous(labels=scales::percent_format())




  ```


  ```{r}
  

tree_map

  ```